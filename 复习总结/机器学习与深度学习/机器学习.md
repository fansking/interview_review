## 机器学习

1. 有监督学习和无监督学习的区别

   **对比一 ： 有标签 vs 无标签**

   有监督机器学习又被称为“有老师的学习”，所谓的老师就是标签。有监督的过程为先通过已知的训练样本（如已知输入和对应的输出）来训练，从而得到一个最优模型，再将这个模型应用在新的数据上，映射为输出结果。再经过这样的过程后，模型就有了预知能力。

   而无监督机器学习被称为“没有老师的学习”，无监督相比于有监督，没有训练的过程，而是直接拿数据进行建模分析，意味着这些都是要通过机器学习自行学习探索。这听起来似乎有点不可思议，但是在我们自身认识世界的过程中也会用到无监督学习。比如我们去参观一个画展，我们对艺术一无所知，但是欣赏完多幅作品之后，我们也能把它们分成不同的派别。比如哪些更朦胧一点，哪些更写实一些。即使我们不知道什么叫做朦胧派和写实派，但是至少我们能把他们分为两个类。

   **对比二 ： 分类 vs 聚类**

   有监督机器学习的核心是分类，无监督机器学习的核心是聚类（将数据集合分成由类似的对象组成的多个类）。有监督的工作是选择分类器和确定权值，无监督的工作是密度估计（寻找描述数据统计值），这意味着无监督算法只要知道如何计算相似度就可以开始工作。

   **对比三 ： 同维 vs 降维**

   有监督的输入如果是n维，特征即被认定为n维，也即y=f(xi)或p(y|xi), i =n，通常不具有降维的能力。而无监督经常要参与深度学习，做特征提取，或者干脆采用层聚类或者项聚类，以减少数据特征的维度。

   **对比四 ：分类同时定性 vs 先聚类后定性**

   有监督的输出结果，也就是分好类的结果会被直接贴上标签，是好还是坏。也即分类分好了，标签也同时贴好了。类似于中药铺的药匣，药剂师采购回来一批药材，需要做的只是把对应的每一颗药材放进贴着标签的药匣中。无监督的结果只是一群一群的聚类，就像被混在一起的多种中药，一个外行要处理这堆药材，能做的只有把看上去一样的药材挑出来聚成很多个小堆。如果要进一步识别这些小堆，就需要一个老中医（类比老师）的指导了。因此，无监督属于先聚类后定性，有点类似于批处理。

   **对比五 ：独立 vs 非独立**

   李航在其著作《统计学习方法》（清华大学出版社）中阐述了一个观点：对于不同的场景，正负样本的分布可能会存在偏移（可能是大的偏移，也可能偏移比较小）。好比我们手动对数据做标注作为训练样本，并把样本画在特征空间中，发现线性非常好，然而在分类面，总有一些混淆的数据样本。对这种现象的一个解释是，不管训练样本（有监督），还是待分类的数据（无监督），并不是所有数据都是相互独立分布的。或者说，数据和数据的分布之间存在联系。作为训练样本，大的偏移很可能会给分类器带来很大的噪声，而对于无监督，情况就会好很多。可见，独立分布数据更适合有监督，非独立数据更适合无监督。

   **对比六 ： 不透明 vs 可解释性**

   由于有监督算法最后输出的一个结果，或者说标签。yes or no，一定是会有一个倾向。但是，如果你想探究为什么这样，有监督会告诉你：因为我们给每个字段乘以了一个参数列[w1, w2, w3…wn]。你继续追问：为什么是这个参数列？为什么第一个字段乘以了0.01而不是0.02？有监督会告诉你：这是我自己学习计算的！然后，就拒绝再回答你的任何问题。是的，有监督算法的分类原因是不具有可解释性的，或者说，是不透明的，因为这些规则都是通过人为建模得出，及其并不能自行产生规则。所以，对于像反洗钱这种需要明确规则的场景，就很难应用。而无监督的聚类方式通常是有很好的解释性的，你问无监督，为什么把他们分成一类？无监督会告诉你，他们有多少特征有多少的一致性，所以才被聚成一组。你恍然大悟，原来如此！于是，进一步可以讲这个特征组总结成规则。如此这般分析，聚类原因便昭然若揭了。

   **对比七 ：DataVisor无监督独有的拓展性**

   试想这样一个n维模型，产出结果已经非常好，这时又增加了一维数据，变成了n+1维。那么，如果这是一个非常强的特征，足以将原来的分类或者聚类打散，一切可能需要从头再来，尤其是有监督，权重值几乎会全部改变。而DataVisor开发的无监督算法，具有极强的扩展性，无论多加的这一维数据的权重有多高，都不影响原来的结果输出，原来的成果仍然可以保留，只需要对多增加的这一维数据做一次处理即可。