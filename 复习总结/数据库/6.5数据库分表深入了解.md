# 6.5数据库优化深入了解

单机数据库可能出现的性能瓶颈有：

- 单个表数据量越大，读写锁，插入操作重新建立索引效率越低
- 单个库数据量太大(一个数据库数据量到1T-2T就是极限)
- 单个数据库服务器压力过大
- 读写速度遇到瓶颈(并发量几百)

主从复制读写分离分离在一定程度上可以缓解数据库压力，但是主从复制也带来其他一系列性能瓶颈问题：

- 写入无法扩展
- 写入无法缓存
- 复制延时
- 锁表率上升
- 表变大，缓存率下降

## 分区

将一张表的数据分成N个区块，在逻辑上看最终只是一张表，但底层是由N个物理区块组成的。这些区块可以在同一个磁盘上，也可以在不同的磁盘上。

由数据库完成，不需要开发者在后端代码中实现分区功能，实际原理与分表类似。

分区是指根据一定的规则，把一个表分解成多个更小更易管理的部分，逻辑上只有一个表或一个索引，但是实际上该表可能由数个物理分区对象组成，每个分区都是一个独立的对象，每个分区可以独自处理，也可以作为表的一部分处理。分区对应用是完全透明的。

传统的分库分表都是在应用层实现，拆分后都要对原有系统进行很大的调整以适应新拆分后的库或表，比如实现一个SQL中间件、原本的联表查询改成两次查询、实现一个全局主键生成器等等。

MySQL分区是在数据库层面，MySQL自己实现的分表功能，在很大程度上简化了分表的难度。

对用户来说，分区是一个独立的逻辑表，但是底层由多个物理子表实现。

也就是说，对于原表分区后，对于应用层来说可以不做变化，无需改变原有的SQL语句，相当于MySQL帮我们实现了传统分表后的SQL中间件

### 分区类型

#### RANGE

根据范围分区，范围应该连续但是不重叠，使用PARTITION BY RANGE, VALUES LESS THAN关键字。不使用COLUMNS关键字时RANGE括号内必须为整数字段名或返回确定整数的函数。可以根据数值范围，TIMESTAMP范围。

#### LIST

根据具体数值分区，每个分区数值不重叠，使用PARTITION BY LIST、VALUES IN关键字。跟Range分区类似，不使用COLUMNS关键字时List括号内必须为整数字段名或返回确定整数的函数。

(范围可不连续，枚举指定)

#### Hash

hash分区，Hash括号内只能是整数列或返回确定整数的函数，实际上就是使用返回的整数对分区数取模。

#### Key分区

是自己指定hash函数，Key分区类似于Hash分区，只不过Hash分区允许使用用户自定义得表达式，而Key分区不允许，需要使用MySQL服务器提供的Hash函数；同时Hash分区只支持整数分区，而Key分区支持除了Blob和Text类型外的所有类型作为分区键。在有主键或者非空唯一键的情况下，创建Key分区时可以不指定分区键，MySQL会默认使用主键作为分区键，若没有主键则使用非空唯一键作为分区键。

#### Columns分区

Columns分区是MySQL5.5引入的新的分区类型，解决了Range分区和List分区只支持整数列的问题，Columns分区支持的分区列类型为：

整数：tinyint、smallint、mediumint、int和bigint

日期时间：date和datetime

字符串类型：char、varchar、binary和varbinary

### 分区缺点

1. 分区表，分区键设计不太灵活，如果不走分区键，很容易出现全表锁
2. 一旦数据量并发量上来，如果在分区表实施关联，就是一个灾难
3. 查询方式由数据库实现，如果出现问题无法及时排查

## 分表

分表的原因

当数据量超大的时候，B-Tree索引就无法起作用了。除非是索引覆盖查询，否则数据库服务器需要根据索引扫描的结果回表，查询所有符合条件的记录，如果数据量巨大，这将产生大量随机I/O，随之，数据库的响应时间将大到不可接受的程度。另外，索引维护(磁盘空间、I/O操作)的代价也非常高。

什么时候考虑分表？

- 一张表的查询速度已经慢到影响使用的时候
-  sql经过优化
- 数据量大
- 当频繁插入或者联合查询时，速度变慢
-  一张表的查询速度已经慢到影响使用的时候。
- 当频繁插入或者联合查询时，速度变慢。

分表解决的问题

- 分表后，单表的并发能力提高了，磁盘I/O性能也提高了，写操作效率提高了
- 查询一次的时间短了
- 数据分布在不同的文件，磁盘I/O性能提高
- 读写锁影响的数据量变小
- 插入数据库需要重新建立索引的数据减少
- 分表的实现方式(复杂)
- 需要业务系统配合迁移升级，工作量较大

水平切和垂直切。

根据前几天的实验，发现数据检索不是性能瓶颈，是回表产生大量的随机I/O带来的性能瓶颈。

## 分库

类似分表

## 分区，分表，分库选择哪一个？

如果你的单机性能很低了，那可以尝试分库。分库，业务透明，在物理实现上分成多个服务器，不同的分库在不同服务器上。分区可以把表分到不同的硬盘上，但不能分配到不同服务器上。一台机器的性能是有限制的，用分库可以解决单台服务器性能不够，或者成本过高问题。

当分区之后，表还是很大，处理不过来，这时候可以用分库。

应该使用哪一种方式来实施数据库分库分表，这要看数据库中数据量的瓶颈所在，并综合项目的业务类型进行考虑。

如果数据库是因为表太多而造成海量数据，并且项目的各项业务逻辑划分清晰、低耦合，那么规则简单明了、容易实施的垂直切分必是首选。

而如果数据库中的表并不多，但单表的数据量很大、或数据热度很高，这种情况之下就应该选择水平切分，水平切分比垂直切分要复杂一些，它将原本逻辑上属于一体的数据进行了物理分割，除了在分割时要对分割的粒度做好评估，考虑数据平均和负载平均，后期也将对项目人员及应用程序产生额外的数据管理负担。

在现实项目中，往往是这两种情况兼而有之，这就需要做出权衡，甚至既需要垂直切分，又需要水平切分。我们的游戏项目便综合使用了垂直与水平切分，我们首先对数据库进行垂直切分，然后，再针对一部分表，通常是用户数据表，进行水平切分。

## 分库、分表带来的后遗症

分库、分表会带来很多的后遗症，会使整个系统架构变的复杂。分的好与不好最关键就是如何寻找那个Sharding key，如果这个Sharding key刚好是业务维度上的分界线就会直接提升性能和改善复杂度，否则就会有各种脚手架来支撑，系统也就会变得复杂。

比如订单系统中的用户__ID__、订单__type__、商家__ID__、渠道__ID__，优惠券系统中的批次__ID__、渠道__ID__、机构__ID__ 等，这些都是潜在的Sharding key。

如果刚好有这么一个Sharding key存在后面处理路由(routing)就会很方便，否则就需要一些大而全的索引表来处理OLAP的查询。

一旦Sharding之后首先要面对的问题就是查询时排序分页问题。

### 跨库join的问题

在拆分之前，系统中很多列表和详情页所需的数据是可以通过sql join来完成的。而拆分后，数据库可能是分布式在不同实例和不同的主机上，join将变得非常麻烦。而且基于架构规范，性能，安全性等方面考虑，一般是禁止跨库join的。那该怎么办呢？首先要考虑下垂直分库的设计问题，如果可以调整，那就优先调整。如果无法调整的情况，下面将结合以往的实际经验，总结几种常见的解决思路，并分析其适用场景。

全局表

所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似我们理解的“数据字典”。为了避免跨库join查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改(甚至几乎不会)，所以也不用太担心“一致性”问题。

字段冗余

这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免join查询。

举个电商业务中很简单的场景：

“订单表”中保存“卖家Id”的同时，将卖家的“Name”字段也冗余，这样查询订单详情的时候就不需要再去查询“卖家用户表”。

字段冗余能带来便利，是一种“空间换时间”的体现。但其适用场景也比较有限，比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证，可以借助数据库中的触发器或者在业务代码层面去保证。当然，也需要结合实际业务场景来看一致性的要求。就像上面例子，如果卖家修改了Name之后，是否需要在订单信息中同步更新呢？

数据同步

A库中的tab_a表和B库中tbl_b有关联，可以定时将指定的表做同步。当然，同步本来会对数据库带来一定的影响，需要性能影响和数据时效性中取得一个平衡。这样来避免复杂的跨库查询。

系统层组装

在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装。说起来很容易，但实践起来可真没有这么简单，尤其是数据库设计上存在问题但又无法轻易调整的时候。具体情况通常会比较复杂。组装的时候要避免循环调用服务，循环RPC，循环查询数据库，最好一次性返回所有信息，在代码里做组装。

在执行了分库分表之后，难以避免会将原本逻辑关联性很强的数据划分到不同的表、不同的库上，这时，表的关联操作将受到限制，我们无法join位于不同分库的表，也无法join分表粒度不同的表，结果原本一次查询能够完成的业务，可能需要多次查询才能完成。

### 跨库事务(分布式事务)的问题

### 分布式全局唯一ID

我们往往直接使用数据库自增特性来生成主键ID，这样确实比较简单。而在分库分表的环境中，数据分布在不同的分片上，不能再借助数据库自增长特性直接生成，否则会造成不同分片上的数据表主键会重复。简单介绍几种ID生成算法。

Twitter的Snowflake(又名“雪花算法”)

UUID/GUID(一般应用程序和数据库均支持)

MongoDB ObjectID(类似UUID的方式)

Ticket Server(数据库生存方式，Flickr采用的就是这种方式)

其中，Twitter 的Snowflake算法生成的是64位唯一Id(由41位的timestamp+ 10位自定义的机器码+ 13位累加计数器组成)。

### 排序问题

需要取前100名，跨库比较

## 测试实验

~~~sql
-- sql语句                                                  #数据量 耗时  
-- SELECT * FROM `t_program` where start_ts < '2020-01-01' # 4.4w 0.472s
-- SELECT * FROM `t_program` where start_ts < '2020-02-01' # 6w 2.91s
-- SELECT * FROM `t_program` where start_ts < '2020-03-01'  # 10W 11.886s
-- SELECT * FROM `t_program` where start_ts < '2020-04-01' # 50W 12s
-- SELECT * FROM `t_program` where start_ts < '2020-05-01' # 80W 13.89s
-- SELECT * FROM `t_program`  # 100w  15.67s
~~~

## 磁盘I/O

https://blog.csdn.net/LJFPHP/article/details/105318995